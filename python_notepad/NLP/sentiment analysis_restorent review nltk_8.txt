        ########### sentiment analysis - restorent review dataset ###########
applyakade restorent review cha dataset aahe jamadhe restorent madhe aalelya locani comment kelyat aaplya restorent la tatla changlya aani wait review cha base vr te aaplya restorent la like kartat ki dislike he 0 aani 1 ne output vr lihlay aapn yacha vapr karun data train test madhe split karun baghuyat.

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
    print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))   #load dataset in google colab

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('Restaurant_Reviews.tsv', delimiter = '\t', quoting = 3)
dataset.head()          #read dataset ithe data ha space ne seprate aahe manun delimenitor ha \t thevlay.
 

len(dataset)             #check lenght of the dataset
dataset.isnull().sum()   #check the any null values present in our dataset or not

#yacha aadhi spacy cha vapar kiva keras madhun analysis kel hot jeki tya yevdya strong library aahet ki te cleaning outomatic kartat pn ithe nltk cha sahayane aapn analysis kartoy je ki aaplala cleaning karavi lagel hatane########

# Cleaning the texts
import re
import nltk
nltk.download('stopwords')
from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords
corpus = []
for i in range(0,1000):
    review = re.sub('[^a-zA-Z]', ' ',dataset['Review'][i])  #one by one row insert karun fkt categorical data ghetla
    review = review.lower()
    review = review.split()
    ps = PorterStemmer()
    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]
    review = ' '.join(review)
    corpus.append(review)      #sagla data clean karun fkt mahavache word vegle kele

# Creating the Bag of Words model
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)   #count vectorizer cha vapar karun imp word che bag of word madhe vector form madhe convert kel
X = cv.fit_transform(corpus).toarray()
y = dataset.iloc[:, 1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)                #traing testing madhe data takla


###khalche veg vegle algorithm takun accuracy baghuyat##

#from sklearn.svm import SVC
#classifier = SVC()
#classifier.fit(X_train,y_train)


#from sklearn.naive_bayes import GaussianNB
#classifier = GaussianNB()
#classifier.fit(X_train, y_train)


#from sklearn.neighbors import KNeighborsClassifier
#classifier = KNeighborsClassifier(n_neighbors=5)
#classifier.fit(X_train, y_train)

#from sklearn.naive_bayes import MultinomialNB
#classifier = MultinomialNB()
#classifier.fit(X_train, y_train)


from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression()
classifier.fit(X_train,y_train)


y_pred = classifier.predict(X_test)

from sklearn import metrics
print(metrics.classification_report(y_test,y_pred))

# Making the Confusion Matrix
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)
print(cm)

print(metrics.accuracy_score(y_test,y_pred))

Logistic Regression = 71
SVC = 73%
GaussianNB  = 73%
MultinomialNB = 76%
KNeighborsClassifier = 61%   varcha vegveglya accuracy aahet
