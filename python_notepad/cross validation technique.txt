       ###############cross validation technique ##############
If dataset are spit in training and testing part so in that case genrally split data in 20% test and 80% train so in that case but 2 catagory in the responce variable but one catagory is more observation are gose on training set becouse we are give data in random manner.so in that case result will not answer in corrent manner so here used the cross validation techniques.

 

# -*- coding: utf-8 -*-
"""
@author: Fahad Hussain
"""
    ####1)bootstrap sample (not imp)########


from sklearn.utils import resample

data = [1, 2, 3, 4, 5, 6]

outputBoot_resample = resample(data, replace=False, n_samples=2, random_state=1)

print('Bootstrap Sample: %s' % outputBoot_resample)

result = [x for x in data if x not in outputBoot_resample]

print('OOB Sample: %s' % result)


     ############holdout cross validation(not use)#######
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn import svm

iris = datasets.load_iris()
iris.data.shape, iris.target.shape


X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.4, random_state=0)

X_train.shape, y_train.shape

X_test.shape, y_test.shape


clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
clf.score(X_test, y_test)  


     ###################one-leave-out ################
here divide all the give and training phase and one observation is testing phase to check similerly one by one we select all observation and give the accuracy. so this is time consuming if data has large.


import numpy as np
from sklearn.cross_validation import LeaveOneOut

X = np.array([[0, 0], [1, 1], [2, 2], [3, 3]])

Y = np.array([0, 1, 0, 1])

loo = LeaveOneOut(len(Y))    #kiti vela exicute karnar manje len(Y)
print(loo)

for train, test in loo:
    print(train, test)

or

from sklearn.model_selection import LeaveOneOut
loc=LeaveOneOut()
loc.get_n_splits(x)  #x manje kiti observation cha data aahe to split zala pahije 100 dile tr 100 vela answer check houn yenar

for train_index,test_index in loc.split(x):
 
x_train,x_test=x[train_index], x[test_index]
y_train,y_test=y[train_index], y[test_index]    
    
or
from sklearn.model_selection import LeaveOneOut
loc=LeaveOneOut()
from sklearn.model_selection import cross_val_score
results_kfold=cross_val_score(r2,x2_data,y2_data,cv=loc)
print(results_kfold)

#Leave-P-Out #####  

from sklearn.cross_validation import LeavePOut
X = [[0, 0], [1, 1], [2, 2], [3, 3]]

Y = [0, 1, 0, 1]

lpo = LeavePOut(len(Y), 2)  #2 means kiti out karayche he aapn ithe sangnar
print(lpo)

for train, test in lpo:
    print(train, test)


   #######KFold###########
yamadhe data che jar 10 fold kele tr sangla data ha 10 equal bhagat divide honar tatla yek bhag ha testing la janar aani bakiche 9 bhag training la aani whatever model apply karun tumi accuracy denar.tya yamule data jo ki vegla vegla asla tri aaplala accuray vegvegli milel aani tacha mean gheun aapn ek accuracy sangu shakto kiva variace baghun kiti datamadhe variation aahe he pn aapn sangu shakto.pn yacha yek drowback asa aahe ki pratek fold madhe sudha variation he asnarch tachamula aaplala modele yevd aacurate ny milnar tachasathi aapn stratified sampling use karto tachamule pratek fold madhe yekraskha pramanat jasta data asel to equally distribute kela jato.

import numpy as np
from sklearn.model_selection import KFold
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
y = np.array([1, 2, 3, 4])
kf = KFold(n_splits=2)
kf.get_n_splits(X)

print(kf)  

for train_index, test_index in kf.split(X):
   print("TRAIN:", train_index, "TEST:", test_index)
   X_train, X_test = X[train_index], X[test_index]
   y_train, y_test = y[train_index], y[test_index]

or

from sklearn.model_selection import KFold
r2=LogistRegression()    #mi he k-fold  logistic regression cha model vr vaprun bghitl
kfold=KFold(10)    #dataset che 10 fold kele

from sklearn.model_selection import cross_val_score
results_kfold=cross_val_score(r2,x2_data,y2_data,cv=kfold)
print(results_kfold)
print(np.mean(results_kfold))
print(np.var(results_kfold))    #check the variation of the data

r2.fit(x2_data,y2_data)
y_pred=r2.predict(x_test)   #model chi pn accuracy bghitly
   
   
   
      ############StratifiedKFold #################
 pratek fold madhe pratek category same yavi manum he use kartat
   
import numpy as np
from sklearn.model_selection import StratifiedKFold
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
y = np.array([0, 0, 1, 1])
skf = StratifiedKFold(n_splits=2)
skf.get_n_splits(X, y)

print(skf)  

for train_index, test_index in skf.split(X, y):
   print("TRAIN:", train_index, "TEST:", test_index)
   X_train, X_test = X[train_index], X[test_index]
   y_train, y_test = y[train_index], y[test_index]

or

from sklearn.model_selection import StratifiedKFold
r2=LogistRegression()   #mi he k-fold  logistic regression cha model vr vaprun bghitl
strata_kfold=StratifiedKFold(n_splits=10)    #dataset che 10 fold kele

from sklearn.model_selection import cross_val_score
results_s_kfold=cross_val_score(r2,x2_data,y2_data,cv=strata_kfold)
print(results_s_kfold)
print(np.mean(results_s_kfold))
print(np.var(results_s_kfold))    #check the variation of the data

r2.fit(x2_data,y2_data)
y_pred=r2.predict(x_test)   #model chi pn accuracy bghitly
   
   
   
#TimeSeriesSplit
   

from sklearn.model_selection import TimeSeriesSplit

X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])
y = np.array([1, 2, 3, 4, 5, 6])

tscv = TimeSeriesSplit(n_splits=3,max_train_size= None)
print(tscv)  

for train, test in tscv.split(X):
    print("%s %s" % (train, test))  
    







##extra information############
'''
 Leave-One-Label-Out - LOLO¶
LeaveOneLabelOut (LOLO) is a cross-validation scheme which holds out the samples according to a third-party provided label.
 This label information can be used to encode arbitrary domain specific stratifications of the samples as integers.

Each training set is thus constituted by all the samples except the ones related to a specific label.

For example, in the cases of multiple experiments, LOLO can be used to create a cross-validation based on the 
different experiments: we create a training set using the samples of all the experiments except one:
'''

from sklearn.cross_validation import LeaveOneLabelOut
X = [[0, 0], [1, 1], [2, 2], [3, 3]]

Y = [0, 1, 0, 1]

labels = [1, 1, 2, 2]

lolo = LeaveOneLabelOut(labels)
print(lolo)

for train, test in lolo:
    print(train, test)
    
    
'''
Leave-P-Label-Out
LeavePLabelOut is similar as Leave-One-Label-Out, but removes samples related to P labels for each 
training/test set.

'''
from sklearn.cross_validation import LeavePLabelOut
X = [[0., 0.], [1., 1.], [-1., -1.], 
     [2., 2.], [3., 3.], [4., 4.]]

Y = [0, 1, 0, 1, 0, 1]

labels = [1, 1, 2, 2, 3, 3]

lplo = LeavePLabelOut(labels, 2)
print(lplo)

for train, test in lplo:
    print(train, test)
    

'''
Random permutations cross-validation a.k.a. Shuffle & Split¶
ShuffleSplit

The ShuffleSplit iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then splitted into a pair of train and test sets.

It is possible to control the randomness for reproducibility of the results by explicitly seeding the random_state pseudo random number generator.

Here is a usage example:
    
    "Random permutation cross-validator

Yields indices to split data into training and test sets.

Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets."

'''

import numpy as np
from sklearn.model_selection import ShuffleSplit
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])

y = np.array([1, 2, 1, 2, 1, 2])

rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)
rs.get_n_splits(X)

print(rs)

for train_index, test_index in rs.split(X):
   print("TRAIN:", train_index, "TEST:", test_index)
 
rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,
                  random_state=0)

for train_index, test_index in rs.split(X):
   print("TRAIN:", train_index, "TEST:", test_index)
   
   
   
   
'''

Time Series CV using Python very basic Example to understand the working ...
'''
   
import numpy as np
from sklearn.model_selection import TimeSeriesSplit
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])

y = np.array([1, 2, 3, 4, 5, 6])

tscv = TimeSeriesSplit(n_splits=5)
print(tscv)  

for train_index, test_index in tscv.split(X):
   print("TRAIN:", train_index, "TEST:", test_index)
   X_train, X_test = X[train_index], X[test_index]
   y_train, y_test = y[train_index], y[test_index]
   


           ###############Gridsurch ###################
parameter he model tache te set kart kiva learn kart pn example la coefficent of linear regression he kiva weight of layer he parameter chi example aahet. hyperparamer chi value aapn set karto aani aapl solution optimize karto example sathi kernel in svm test_size in in traning testing phase these are the hperparameters.
hperparameter yek nasto aaplakde bharpur astat tatla nakki konta aapn aaplya model sathi thik aahe he bghnyasathi gridsurch vapartat tumi imp vatnar barpur hyperparameter dya tacha according tumala solution bhetel.

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('LR.csv')
X = dataset.iloc[:, [0,1]].values
y = dataset.iloc[:, 2].values

#Training and Testing Data (divide the data into two part)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.25, random_state=0)

from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.fit_transform(X_test)

from sklearn.svm import SVC
classifer=SVC(kernel='rbf',random_state=0,gamma=0.3)
classifer.fit(X_train,y_train)


y_pred = classifer.predict(X_test)


from sklearn.metrics import confusion_matrix
cm =confusion_matrix(y_test, y_pred)


from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

from sklearn.model_selection import cross_val_score
accuracies = cross_val_score(estimator =classifer,X =X_train, y= y_train, cv= 10)
accuracies.mean()
accuracies.std()            #kfold technique cha vapar karun aapn bghitl ki accuracy kiti aahe model chi pn aapn yat hyper parameter tunning ny karat.


from sklearn.model_selection import GridSearchCV              #ithe konte parameter tune karayche te dile
parameters = [{'C': [1,10,100,1000],'kernel' : ['linear']},
               {'C': [1,10,100,1000],'kernel': ['rbf'],
                'gamma':[0.1,0.2,0.3,0.4,0.5,0.6,0.7]
                    }]

grid_search = GridSearchCV(estimator=classifer, param_grid=parameters, scoring ='accuracy', cv=10,n_jobs=1 )
grid_search = grid_search.fit(X_train, y_train)
best_accuracy = grid_search.best_score_             #high accuracy yeil
best_parameters = grid_search.best_params_          #model sathi konte hyper parameter imp aahet te disel



# Visualising the Training set results
from matplotlib.colors import ListedColormap
X_set, y_set = X_train, y_train
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifer.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Classifier (Training set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()                                  #this is visuallizarion of x train

# Visualising the Test set results
from matplotlib.colors import ListedColormap
X_set, y_set = X_test, y_test
X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),
                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))
plt.contourf(X1, X2, classifer.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),
             alpha = 0.75, cmap = ListedColormap(('red', 'green')))
plt.xlim(X1.min(), X1.max())
plt.ylim(X2.min(), X2.max())
for i, j in enumerate(np.unique(y_set)):
    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],
                c = ListedColormap(('red', 'green'))(i), label = j)
plt.title('Classifier (Test set)')
plt.xlabel('Age')
plt.ylabel('Estimated Salary')
plt.legend()
plt.show()                               #this is visualisation of testing dataset